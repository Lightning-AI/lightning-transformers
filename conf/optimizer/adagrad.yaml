# @package _group_
_target_: torch.optim.Adagrad
lr: ${training.lr}
